{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9B_EK4Me9ix"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "url = \"https://drive.google.com/uc?id=1Q4J8KS1wm4-_YTuc389enPh6O-eTNcx2\"\n",
        "diabetes_data = pd.read_csv(url)\n",
        "\n",
        "# Step 2: Examine the dataset\n",
        "print(\"Data Preview:\")\n",
        "print(diabetes_data.head())\n",
        "\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(diabetes_data.describe())\n",
        "\n",
        "print(\"\\nInfo about the dataset:\")\n",
        "print(diabetes_data.info())\n",
        "\n",
        "# Step 3: Visualizations to understand distributions\n",
        "# Distribution of numerical variables\n",
        "diabetes_data.hist(bins=20, figsize=(15, 10))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correlation heatmap to check relationships between variables\n",
        "corr = diabetes_data.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# Pairplot for understanding relationships between features and outcome\n",
        "sns.pairplot(diabetes_data, hue='Outcome', diag_kind='hist')\n",
        "plt.show()\n",
        "\n",
        "# Step 4: Handle missing values\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values in the dataset:\")\n",
        "print(diabetes_data.isnull().sum())\n",
        "\n",
        "# Replace missing values with median for numerical columns\n",
        "diabetes_data.fillna(diabetes_data.median(), inplace=True)\n",
        "\n",
        "# Step 5: Remove outliers using IQR method\n",
        "Q1 = diabetes_data.quantile(0.25)\n",
        "Q3 = diabetes_data.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "filtered_data = diabetes_data[~((diabetes_data < (Q1 - 1.5 * IQR)) | (diabetes_data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# Step 6: Split the dataset into training and testing sets\n",
        "X = filtered_data.drop('Outcome', axis=1)\n",
        "y = filtered_data['Outcome']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"Training data: {X_train.shape}, Test data: {X_test.shape}\")\n",
        "\n",
        "# Step 7: Hyperparameter tuning using GridSearchCV\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters found by GridSearchCV\n",
        "print(f\"\\nBest Hyperparameters: {grid_search.best_params_}\")\n",
        "\n",
        "# Step 8: Train the model with the best hyperparameters\n",
        "best_dt_model = grid_search.best_estimator_\n",
        "best_dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 9: Evaluate the model on the test set\n",
        "y_pred = best_dt_model.predict(X_test)\n",
        "\n",
        "# Step 10: Calculate and display performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nModel Performance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Diabetic', 'Diabetic'], yticklabels=['Non-Diabetic', 'Diabetic'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, best_dt_model.predict_proba(X_test)[:, 1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Step 11: Visualize the decision tree\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(best_dt_model, filled=True, feature_names=X.columns, class_names=['Non-Diabetic', 'Diabetic'], fontsize=10)\n",
        "plt.title('Decision Tree Visualization')\n",
        "plt.show()\n",
        "\n",
        "# Step 12: Check feature importance\n",
        "importance = best_dt_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': importance\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_importance_df)\n",
        "\n",
        "# Step 13: Sensitivity analysis to test model robustness\n",
        "X_test_noisy = X_test.copy()\n",
        "X_test_noisy['Glucose'] += np.random.normal(0, 0.1, size=X_test_noisy.shape[0])\n",
        "\n",
        "# Predict on the noisy test set\n",
        "y_pred_noisy = best_dt_model.predict(X_test_noisy)\n",
        "\n",
        "# Evaluate the performance on the noisy data\n",
        "roc_auc_noisy = auc(*roc_curve(y_test, best_dt_model.predict_proba(X_test_noisy)[:, 1])[:2])\n",
        "print(f\"\\nROC AUC with noisy data: {roc_auc_noisy}\")\n"
      ]
    }
  ]
}